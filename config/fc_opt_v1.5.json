{
    "agent": {
        "layers": [
            "# These layers should describe all but the input and output layers. Those are handled by the system.",
            "# Reduce incoming 6D tensor to 5D by merging channels (dim 1) and one-hot (dim 5):",
            "keras.layers.Permute((2, 3, 4, 1, 5))",
            "keras.layers.Reshape(({observation_width}, {observation_height}, {observation_width}, 2*{num_inputs}))",
            "# Convolve each input, treating the blueprint and world state as separate channels",
            "keras.layers.Conv3D(16, (3, 2, 3), padding='valid', data_format='channels_last', activation='elu')",
            "keras.layers.Conv3D(8, (3, 1, 3), padding='valid', data_format='channels_last', activation='elu')",
            "# Flatten, ready for fully-connected layers:",
            "keras.layers.Flatten()",
            "# Do some thinking:",
            "keras.layers.Dense(32, activation='elu')",
            "keras.layers.Dense(16, activation='elu')",
            "# Use a linear activation on the output layer because Q values can be in any range.",
            "keras.layers.Dense({num_actions}, activation='linear')"
        ],
        "auto_final_layer": false,
        "use_full_observation": false,
        "observation_width": 9,
        "observation_height": 5,
        "obs_edge_type": "edge"
    },
    "training": {
        "num_episodes": 1000,
        "save_frequency": 50,
        "max_episode_time": 3,
        "initial_epsilon": 0.8,
        "final_epsilon": 0.005,
        "overclock_factor": 5,
        "save_history": false,
        "train_on_history": false,
        "history": {
            "batch_size": 512,
            "batches": 32,
            "epochs": 32
        },
        "reward_weight": {
            "base": -0.002,
            "distance": 0.001,
            "facing_incomplete": 0.001,
            "place_necessary": 0.5,
            "place_superfluous": -0.5,
            "attack_floor": -1,
            "leave_arena": -1,
            "mission_complete": 1
        }
    },
    "curriculum": {
        "observation_period": 15,
        "max_lesson_length": 1200,
        "lessons": [
            {
                "name": "lessonMB",
                "params": {
                    "n_blocks": 10,
                    "k": 1,
                    "target_reward": 2.0
                },
                "max_episodes": 4000,
                "max_episode_time": 20,
                "set_learning_schedule": true
            },
            {
                "name": "lessonMB",
                "params": {
                    "k": 1,
                    "organized": "random",
                    "floor_size_x": 3,
                    "floor_size_z": 3,
                    "n_blocks": 4,
                    "tower": true,
                    "max_height": 4,
                    "random_height": false
                },
                "max_episodes": 1000,
                "max_episode_time": 20,
                "set_learning_schedule": true
            }
        ]
    },
    "arena": {
        "width": 10,
        "height": 5,
        "length": 10,
        "anchor": {
            "x": 0,
            "y": 5,
            "z": 0
        },
        "offset": {
            "x": 0.5,
            "y": 0,
            "z": 0.5
        }
    },
    "inputs": ["air", "stone", "edge"],
    "actions": ["jumpmove 1", "turn 1", "turn -1", "use"]
}
