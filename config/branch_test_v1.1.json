{
    "agent": {
        "layers": [
            "# These layers should describe all but the input and output layers. Those are handled by the system.",
            "# Reduce incoming 6D tensor to 5D by merging channels (dim 1) and one-hot (dim 5):",
            "keras.layers.Permute((2, 3, 4, 1, 5))",
            "keras.layers.Reshape(({observation_width}, {observation_height}, {observation_width}, 2*{num_inputs}))",
            "# Convolve each input, treating the blueprint and world state as separate channels",
            "keras.layers.Conv3D(8, (4, 2, 4), padding='same', data_format='channels_last', activation='relu')",
            "keras.layers.Conv3D(8, (2, 1, 2), padding='same', data_format='channels_last', activation='relu')",
            "# max-pool features together a bit:",
            "keras.layers.MaxPooling3D(pool_size=(2, 1, 2), data_format='channels_last')",
            "# Flatten, ready for fully-connected layers:",
            "keras.layers.Flatten()",
            "# Do some thinking:",
            [
              "# This splits the model into two branches:",
              [
                "# This is the value branch:",
                "keras.layers.Dense(16, activation='relu', name='fully-connected_1')",
                "keras.layers.Dense(1, activation='relu', name='value')"
              ],
              [
                "# This is the advantage branch:",
                "keras.layers.Dense(16, activation='relu', name='fully-connected_2')",
                "keras.layers.Dense({num_actions}, activation='relu', name='advantage')"
              ],
              "# This merges the model:",
              "M:keras.layers.Lambda(lambda x: x[1]-K.mean(x[1])+x[0], ({num_actions},), name='policy')"
            ]
        ],
        "auto_final_layer": false,
        "use_full_observation": false,
        "observation_width": 5,
        "observation_height": 3,
        "non_sequnetial": true,
        "reload_at_checkpoint": false
    },
    "training": {
        "num_episodes": 1000,
        "save_frequency": 50,
        "max_episode_time": 3,
        "initial_epsilon": 0.9,
        "final_epsilon": 0.05,
        "overclock_factor": 6,
        "save_history": false,
        "train_on_history": false,
        "history": {
            "batch_size": 512,
            "batches": 32,
            "epochs": 32
        },
        "reward_weight": {
            "base": -0.002,
            "distance": 0.001,
            "facing_incomplete": 0.001,
            "place_necessary": 0.5,
            "place_superfluous": -0.5,
            "attack_floor": -1,
            "leave_arena": -1,
            "mission_complete": 1
        }
    },
    "curriculum": {
        "observation_period": 15,
        "max_lesson_length": 1200,
        "lessons": [
          {
              "name": "in_front",
              "params": {},
              "max_episodes": 200,
              "max_episode_time": 1,
              "set_learning_schedule": true
          },
          {
              "name": "turn",
              "params": {},
              "max_episodes": 400,
              "max_episode_time": 1,
              "target_reward": 0.95,
              "set_learning_schedule": true
          },
          {
              "name": "approach",
              "params": {
                  "max_distance": 3
              },
              "max_episodes": 400,
              "max_episode_time": 1.5,
              "target_reward": 0.95,
              "set_learning_schedule": true
          },
          {
                "name": "lessonA",
                "params": {
                    "k": 1
                },
                "max_episodes": 600,
                "max_episode_time": 3,
                "target_reward": 0.75,
                "set_learning_schedule": true
            },
            {
                  "name": "lessonA",
                  "params": {
                      "k": 2
                  },
                  "max_episodes": 600,
                  "max_episode_time": 3,
                  "target_reward": 0.75,
                  "set_learning_schedule": true
            },
            {
                  "name": "lessonA",
                  "params": {
                      "k": 4
                  },
                  "max_episodes": 600,
                  "max_episode_time": 3,
                  "target_reward": 0.75,
                  "set_learning_schedule": true
            },
            {
                  "name": "lessonA",
                  "params": {
                      "k": 6
                  },
                  "max_episodes": 600,
                  "max_episode_time": 3,
                  "target_reward": 0.75,
                  "set_learning_schedule": true
            },
            {
                "name": "lessonB",
                "params": {},
                "max_episodes": 1000,
                "max_episode_time": 3,
                "target_reward": 0.75,
                "set_learning_schedule": true
            },
            {
                "name": "lessonC",
                "params": {
                  "n_blocks": 3
                },
                "max_episodes": 1000,
                "max_episode_time": 8,
                "target_reward": 0.75,
                "set_learning_schedule": true
            },
            {
                "name": "lessonD",
                "params": {
                  "organized": "random"
                },
                "max_episodes": 1000,
                "max_episode_time": 8,
                "set_learning_schedule": true
            },
            {
                "name": "lessonD",
                "params": {
                  "organized": "floor",
                  "floor_size_x": 2,
                  "floor_size_z": 2
                },
                "max_episodes": 1000,
                "max_episode_time": 8,
                "target_reward": 0.75,
                "set_learning_schedule": true
            }
        ]
    },
    "arena": {
        "width": 8,
        "height": 4,
        "length": 8,
        "anchor": {
            "x": 0,
            "y": 5,
            "z": 0
        },
        "offset": {
            "x": 0.5,
            "y": 0,
            "z": 0.5
        }
    },
    "inputs": ["air", "stone"],
    "actions": ["jumpmove 1", "turn 1", "turn -1", "use", "attack"]
}
